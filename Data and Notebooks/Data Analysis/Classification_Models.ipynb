{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proxgrad_const"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, Plots, LowRankModels, CSV, LinearAlgebra, Statistics, ScikitLearn, Random, Distributions\n",
    "include(\"proxgrad.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th><th>Date</th><th>Reddit Post Count</th><th>Twitter Post Count</th><th>Company</th><th>Reddit Upvote Sum</th></tr><tr><th></th><th>Int64</th><th>Date…</th><th>Int64</th><th>Int64</th><th>String</th><th>Int64</th></tr></thead><tbody><p>320 rows × 10 columns (omitted printing of 4 columns)</p><tr><th>1</th><td>0</td><td>0020-07-01</td><td>1</td><td>317034</td><td>FB</td><td>0</td></tr><tr><th>2</th><td>1</td><td>0020-07-02</td><td>2</td><td>297197</td><td>FB</td><td>12</td></tr><tr><th>3</th><td>2</td><td>0020-07-06</td><td>0</td><td>278204</td><td>FB</td><td>0</td></tr><tr><th>4</th><td>3</td><td>0020-07-07</td><td>1</td><td>309570</td><td>FB</td><td>2</td></tr><tr><th>5</th><td>4</td><td>0020-07-08</td><td>3</td><td>338002</td><td>FB</td><td>81</td></tr><tr><th>6</th><td>5</td><td>0020-07-09</td><td>0</td><td>285488</td><td>FB</td><td>0</td></tr><tr><th>7</th><td>6</td><td>0020-07-10</td><td>0</td><td>329350</td><td>FB</td><td>0</td></tr><tr><th>8</th><td>7</td><td>0020-07-13</td><td>1</td><td>321903</td><td>FB</td><td>1</td></tr><tr><th>9</th><td>8</td><td>0020-07-14</td><td>1</td><td>314377</td><td>FB</td><td>3</td></tr><tr><th>10</th><td>9</td><td>0020-07-15</td><td>1</td><td>310177</td><td>FB</td><td>1</td></tr><tr><th>11</th><td>10</td><td>0020-07-16</td><td>3</td><td>299657</td><td>FB</td><td>5</td></tr><tr><th>12</th><td>11</td><td>0020-07-17</td><td>2</td><td>289229</td><td>FB</td><td>2</td></tr><tr><th>13</th><td>12</td><td>0020-07-20</td><td>0</td><td>303463</td><td>FB</td><td>0</td></tr><tr><th>14</th><td>13</td><td>0020-07-21</td><td>0</td><td>280269</td><td>FB</td><td>0</td></tr><tr><th>15</th><td>14</td><td>0020-07-22</td><td>2</td><td>300984</td><td>FB</td><td>2</td></tr><tr><th>16</th><td>15</td><td>0020-07-23</td><td>0</td><td>296316</td><td>FB</td><td>0</td></tr><tr><th>17</th><td>16</td><td>0020-07-24</td><td>5</td><td>280804</td><td>FB</td><td>41</td></tr><tr><th>18</th><td>17</td><td>0020-07-27</td><td>2</td><td>301834</td><td>FB</td><td>6</td></tr><tr><th>19</th><td>18</td><td>0020-07-28</td><td>1</td><td>360667</td><td>FB</td><td>1</td></tr><tr><th>20</th><td>19</td><td>0020-07-29</td><td>2</td><td>336169</td><td>FB</td><td>2</td></tr><tr><th>21</th><td>20</td><td>0020-07-30</td><td>1</td><td>304231</td><td>FB</td><td>0</td></tr><tr><th>22</th><td>21</td><td>0020-07-31</td><td>9</td><td>278417</td><td>FB</td><td>240</td></tr><tr><th>23</th><td>22</td><td>0020-08-03</td><td>2</td><td>289507</td><td>FB</td><td>3</td></tr><tr><th>24</th><td>23</td><td>0020-08-04</td><td>1</td><td>405487</td><td>FB</td><td>0</td></tr><tr><th>25</th><td>24</td><td>0020-08-05</td><td>0</td><td>353367</td><td>FB</td><td>0</td></tr><tr><th>26</th><td>25</td><td>0020-08-06</td><td>0</td><td>355203</td><td>FB</td><td>0</td></tr><tr><th>27</th><td>26</td><td>0020-08-07</td><td>3</td><td>362076</td><td>FB</td><td>3</td></tr><tr><th>28</th><td>27</td><td>0020-08-10</td><td>1</td><td>312615</td><td>FB</td><td>1</td></tr><tr><th>29</th><td>28</td><td>0020-08-11</td><td>2</td><td>320465</td><td>FB</td><td>91</td></tr><tr><th>30</th><td>29</td><td>0020-08-12</td><td>0</td><td>436852</td><td>FB</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Column1 & Date & Reddit Post Count & Twitter Post Count & Company & Reddit Upvote Sum & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Date… & Int64 & Int64 & String & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0020-07-01 & 1 & 317034 & FB & 0 & $\\dots$ \\\\\n",
       "\t2 & 1 & 0020-07-02 & 2 & 297197 & FB & 12 & $\\dots$ \\\\\n",
       "\t3 & 2 & 0020-07-06 & 0 & 278204 & FB & 0 & $\\dots$ \\\\\n",
       "\t4 & 3 & 0020-07-07 & 1 & 309570 & FB & 2 & $\\dots$ \\\\\n",
       "\t5 & 4 & 0020-07-08 & 3 & 338002 & FB & 81 & $\\dots$ \\\\\n",
       "\t6 & 5 & 0020-07-09 & 0 & 285488 & FB & 0 & $\\dots$ \\\\\n",
       "\t7 & 6 & 0020-07-10 & 0 & 329350 & FB & 0 & $\\dots$ \\\\\n",
       "\t8 & 7 & 0020-07-13 & 1 & 321903 & FB & 1 & $\\dots$ \\\\\n",
       "\t9 & 8 & 0020-07-14 & 1 & 314377 & FB & 3 & $\\dots$ \\\\\n",
       "\t10 & 9 & 0020-07-15 & 1 & 310177 & FB & 1 & $\\dots$ \\\\\n",
       "\t11 & 10 & 0020-07-16 & 3 & 299657 & FB & 5 & $\\dots$ \\\\\n",
       "\t12 & 11 & 0020-07-17 & 2 & 289229 & FB & 2 & $\\dots$ \\\\\n",
       "\t13 & 12 & 0020-07-20 & 0 & 303463 & FB & 0 & $\\dots$ \\\\\n",
       "\t14 & 13 & 0020-07-21 & 0 & 280269 & FB & 0 & $\\dots$ \\\\\n",
       "\t15 & 14 & 0020-07-22 & 2 & 300984 & FB & 2 & $\\dots$ \\\\\n",
       "\t16 & 15 & 0020-07-23 & 0 & 296316 & FB & 0 & $\\dots$ \\\\\n",
       "\t17 & 16 & 0020-07-24 & 5 & 280804 & FB & 41 & $\\dots$ \\\\\n",
       "\t18 & 17 & 0020-07-27 & 2 & 301834 & FB & 6 & $\\dots$ \\\\\n",
       "\t19 & 18 & 0020-07-28 & 1 & 360667 & FB & 1 & $\\dots$ \\\\\n",
       "\t20 & 19 & 0020-07-29 & 2 & 336169 & FB & 2 & $\\dots$ \\\\\n",
       "\t21 & 20 & 0020-07-30 & 1 & 304231 & FB & 0 & $\\dots$ \\\\\n",
       "\t22 & 21 & 0020-07-31 & 9 & 278417 & FB & 240 & $\\dots$ \\\\\n",
       "\t23 & 22 & 0020-08-03 & 2 & 289507 & FB & 3 & $\\dots$ \\\\\n",
       "\t24 & 23 & 0020-08-04 & 1 & 405487 & FB & 0 & $\\dots$ \\\\\n",
       "\t25 & 24 & 0020-08-05 & 0 & 353367 & FB & 0 & $\\dots$ \\\\\n",
       "\t26 & 25 & 0020-08-06 & 0 & 355203 & FB & 0 & $\\dots$ \\\\\n",
       "\t27 & 26 & 0020-08-07 & 3 & 362076 & FB & 3 & $\\dots$ \\\\\n",
       "\t28 & 27 & 0020-08-10 & 1 & 312615 & FB & 1 & $\\dots$ \\\\\n",
       "\t29 & 28 & 0020-08-11 & 2 & 320465 & FB & 91 & $\\dots$ \\\\\n",
       "\t30 & 29 & 0020-08-12 & 0 & 436852 & FB & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "320×10 DataFrame. Omitted printing of 6 columns\n",
       "│ Row │ Column1 │ Date       │ Reddit Post Count │ Twitter Post Count │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mDates.Date\u001b[39m │ \u001b[90mInt64\u001b[39m             │ \u001b[90mInt64\u001b[39m              │\n",
       "├─────┼─────────┼────────────┼───────────────────┼────────────────────┤\n",
       "│ 1   │ 0       │ 0020-07-01 │ 1                 │ 317034             │\n",
       "│ 2   │ 1       │ 0020-07-02 │ 2                 │ 297197             │\n",
       "│ 3   │ 2       │ 0020-07-06 │ 0                 │ 278204             │\n",
       "│ 4   │ 3       │ 0020-07-07 │ 1                 │ 309570             │\n",
       "│ 5   │ 4       │ 0020-07-08 │ 3                 │ 338002             │\n",
       "│ 6   │ 5       │ 0020-07-09 │ 0                 │ 285488             │\n",
       "│ 7   │ 6       │ 0020-07-10 │ 0                 │ 329350             │\n",
       "│ 8   │ 7       │ 0020-07-13 │ 1                 │ 321903             │\n",
       "│ 9   │ 8       │ 0020-07-14 │ 1                 │ 314377             │\n",
       "│ 10  │ 9       │ 0020-07-15 │ 1                 │ 310177             │\n",
       "⋮\n",
       "│ 310 │ 309     │ 0020-09-16 │ 2                 │ 1205               │\n",
       "│ 311 │ 310     │ 0020-09-17 │ 0                 │ 1426               │\n",
       "│ 312 │ 311     │ 0020-09-18 │ 0                 │ 1516               │\n",
       "│ 313 │ 312     │ 0020-09-21 │ 0                 │ 1241               │\n",
       "│ 314 │ 313     │ 0020-09-22 │ 0                 │ 1248               │\n",
       "│ 315 │ 314     │ 0020-09-23 │ 0                 │ 1329               │\n",
       "│ 316 │ 315     │ 0020-09-24 │ 0                 │ 1282               │\n",
       "│ 317 │ 316     │ 0020-09-25 │ 1                 │ 1261               │\n",
       "│ 318 │ 317     │ 0020-09-28 │ 0                 │ 1241               │\n",
       "│ 319 │ 318     │ 0020-09-29 │ 2                 │ 1822               │\n",
       "│ 320 │ 319     │ 0020-09-30 │ 0                 │ 1255               │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CSV.read(\"FinalDataSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on all data at once. Logistic Loss, Quadratic Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = data[:Returns]\n",
    "features = data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4765625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate model for each company. Logistic Loss, Quadratic Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th><th>Date</th><th>Reddit Post Count</th><th>Twitter Post Count</th><th>Company</th><th>Reddit Upvote Sum</th></tr><tr><th></th><th>Int64</th><th>Date…</th><th>Int64</th><th>Int64</th><th>String</th><th>Int64</th></tr></thead><tbody><p>64 rows × 10 columns (omitted printing of 4 columns)</p><tr><th>1</th><td>256</td><td>0020-07-01</td><td>0</td><td>1286</td><td>GOOG</td><td>0</td></tr><tr><th>2</th><td>257</td><td>0020-07-02</td><td>4</td><td>1070</td><td>GOOG</td><td>38</td></tr><tr><th>3</th><td>258</td><td>0020-07-06</td><td>1</td><td>1073</td><td>GOOG</td><td>8</td></tr><tr><th>4</th><td>259</td><td>0020-07-07</td><td>1</td><td>1187</td><td>GOOG</td><td>3</td></tr><tr><th>5</th><td>260</td><td>0020-07-08</td><td>1</td><td>1094</td><td>GOOG</td><td>1</td></tr><tr><th>6</th><td>261</td><td>0020-07-09</td><td>2</td><td>1081</td><td>GOOG</td><td>4</td></tr><tr><th>7</th><td>262</td><td>0020-07-10</td><td>2</td><td>1425</td><td>GOOG</td><td>2</td></tr><tr><th>8</th><td>263</td><td>0020-07-13</td><td>0</td><td>1326</td><td>GOOG</td><td>0</td></tr><tr><th>9</th><td>264</td><td>0020-07-14</td><td>3</td><td>1268</td><td>GOOG</td><td>26</td></tr><tr><th>10</th><td>265</td><td>0020-07-15</td><td>3</td><td>1223</td><td>GOOG</td><td>103</td></tr><tr><th>11</th><td>266</td><td>0020-07-16</td><td>0</td><td>1247</td><td>GOOG</td><td>0</td></tr><tr><th>12</th><td>267</td><td>0020-07-17</td><td>3</td><td>1056</td><td>GOOG</td><td>1</td></tr><tr><th>13</th><td>268</td><td>0020-07-20</td><td>2</td><td>1118</td><td>GOOG</td><td>3</td></tr><tr><th>14</th><td>269</td><td>0020-07-21</td><td>1</td><td>1315</td><td>GOOG</td><td>1</td></tr><tr><th>15</th><td>270</td><td>0020-07-22</td><td>0</td><td>1243</td><td>GOOG</td><td>0</td></tr><tr><th>16</th><td>271</td><td>0020-07-23</td><td>2</td><td>1139</td><td>GOOG</td><td>2</td></tr><tr><th>17</th><td>272</td><td>0020-07-24</td><td>5</td><td>1226</td><td>GOOG</td><td>39</td></tr><tr><th>18</th><td>273</td><td>0020-07-27</td><td>1</td><td>1465</td><td>GOOG</td><td>0</td></tr><tr><th>19</th><td>274</td><td>0020-07-28</td><td>0</td><td>1267</td><td>GOOG</td><td>0</td></tr><tr><th>20</th><td>275</td><td>0020-07-29</td><td>1</td><td>2340</td><td>GOOG</td><td>1</td></tr><tr><th>21</th><td>276</td><td>0020-07-30</td><td>1</td><td>3343</td><td>GOOG</td><td>0</td></tr><tr><th>22</th><td>277</td><td>0020-07-31</td><td>9</td><td>2805</td><td>GOOG</td><td>370</td></tr><tr><th>23</th><td>278</td><td>0020-08-03</td><td>1</td><td>1545</td><td>GOOG</td><td>7</td></tr><tr><th>24</th><td>279</td><td>0020-08-04</td><td>2</td><td>1177</td><td>GOOG</td><td>1</td></tr><tr><th>25</th><td>280</td><td>0020-08-05</td><td>2</td><td>937</td><td>GOOG</td><td>1</td></tr><tr><th>26</th><td>281</td><td>0020-08-06</td><td>2</td><td>1103</td><td>GOOG</td><td>13</td></tr><tr><th>27</th><td>282</td><td>0020-08-07</td><td>2</td><td>1168</td><td>GOOG</td><td>1</td></tr><tr><th>28</th><td>283</td><td>0020-08-10</td><td>0</td><td>1289</td><td>GOOG</td><td>0</td></tr><tr><th>29</th><td>284</td><td>0020-08-11</td><td>2</td><td>1513</td><td>GOOG</td><td>1</td></tr><tr><th>30</th><td>285</td><td>0020-08-12</td><td>1</td><td>1495</td><td>GOOG</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Column1 & Date & Reddit Post Count & Twitter Post Count & Company & Reddit Upvote Sum & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Date… & Int64 & Int64 & String & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 256 & 0020-07-01 & 0 & 1286 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t2 & 257 & 0020-07-02 & 4 & 1070 & GOOG & 38 & $\\dots$ \\\\\n",
       "\t3 & 258 & 0020-07-06 & 1 & 1073 & GOOG & 8 & $\\dots$ \\\\\n",
       "\t4 & 259 & 0020-07-07 & 1 & 1187 & GOOG & 3 & $\\dots$ \\\\\n",
       "\t5 & 260 & 0020-07-08 & 1 & 1094 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t6 & 261 & 0020-07-09 & 2 & 1081 & GOOG & 4 & $\\dots$ \\\\\n",
       "\t7 & 262 & 0020-07-10 & 2 & 1425 & GOOG & 2 & $\\dots$ \\\\\n",
       "\t8 & 263 & 0020-07-13 & 0 & 1326 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t9 & 264 & 0020-07-14 & 3 & 1268 & GOOG & 26 & $\\dots$ \\\\\n",
       "\t10 & 265 & 0020-07-15 & 3 & 1223 & GOOG & 103 & $\\dots$ \\\\\n",
       "\t11 & 266 & 0020-07-16 & 0 & 1247 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t12 & 267 & 0020-07-17 & 3 & 1056 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t13 & 268 & 0020-07-20 & 2 & 1118 & GOOG & 3 & $\\dots$ \\\\\n",
       "\t14 & 269 & 0020-07-21 & 1 & 1315 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t15 & 270 & 0020-07-22 & 0 & 1243 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t16 & 271 & 0020-07-23 & 2 & 1139 & GOOG & 2 & $\\dots$ \\\\\n",
       "\t17 & 272 & 0020-07-24 & 5 & 1226 & GOOG & 39 & $\\dots$ \\\\\n",
       "\t18 & 273 & 0020-07-27 & 1 & 1465 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t19 & 274 & 0020-07-28 & 0 & 1267 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t20 & 275 & 0020-07-29 & 1 & 2340 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t21 & 276 & 0020-07-30 & 1 & 3343 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t22 & 277 & 0020-07-31 & 9 & 2805 & GOOG & 370 & $\\dots$ \\\\\n",
       "\t23 & 278 & 0020-08-03 & 1 & 1545 & GOOG & 7 & $\\dots$ \\\\\n",
       "\t24 & 279 & 0020-08-04 & 2 & 1177 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t25 & 280 & 0020-08-05 & 2 & 937 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t26 & 281 & 0020-08-06 & 2 & 1103 & GOOG & 13 & $\\dots$ \\\\\n",
       "\t27 & 282 & 0020-08-07 & 2 & 1168 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t28 & 283 & 0020-08-10 & 0 & 1289 & GOOG & 0 & $\\dots$ \\\\\n",
       "\t29 & 284 & 0020-08-11 & 2 & 1513 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t30 & 285 & 0020-08-12 & 1 & 1495 & GOOG & 1 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "64×10 DataFrame. Omitted printing of 6 columns\n",
       "│ Row │ Column1 │ Date       │ Reddit Post Count │ Twitter Post Count │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mDates.Date\u001b[39m │ \u001b[90mInt64\u001b[39m             │ \u001b[90mInt64\u001b[39m              │\n",
       "├─────┼─────────┼────────────┼───────────────────┼────────────────────┤\n",
       "│ 1   │ 256     │ 0020-07-01 │ 0                 │ 1286               │\n",
       "│ 2   │ 257     │ 0020-07-02 │ 4                 │ 1070               │\n",
       "│ 3   │ 258     │ 0020-07-06 │ 1                 │ 1073               │\n",
       "│ 4   │ 259     │ 0020-07-07 │ 1                 │ 1187               │\n",
       "│ 5   │ 260     │ 0020-07-08 │ 1                 │ 1094               │\n",
       "│ 6   │ 261     │ 0020-07-09 │ 2                 │ 1081               │\n",
       "│ 7   │ 262     │ 0020-07-10 │ 2                 │ 1425               │\n",
       "│ 8   │ 263     │ 0020-07-13 │ 0                 │ 1326               │\n",
       "│ 9   │ 264     │ 0020-07-14 │ 3                 │ 1268               │\n",
       "│ 10  │ 265     │ 0020-07-15 │ 3                 │ 1223               │\n",
       "⋮\n",
       "│ 54  │ 309     │ 0020-09-16 │ 2                 │ 1205               │\n",
       "│ 55  │ 310     │ 0020-09-17 │ 0                 │ 1426               │\n",
       "│ 56  │ 311     │ 0020-09-18 │ 0                 │ 1516               │\n",
       "│ 57  │ 312     │ 0020-09-21 │ 0                 │ 1241               │\n",
       "│ 58  │ 313     │ 0020-09-22 │ 0                 │ 1248               │\n",
       "│ 59  │ 314     │ 0020-09-23 │ 0                 │ 1329               │\n",
       "│ 60  │ 315     │ 0020-09-24 │ 0                 │ 1282               │\n",
       "│ 61  │ 316     │ 0020-09-25 │ 1                 │ 1261               │\n",
       "│ 62  │ 317     │ 0020-09-28 │ 0                 │ 1241               │\n",
       "│ 63  │ 318     │ 0020-09-29 │ 2                 │ 1822               │\n",
       "│ 64  │ 319     │ 0020-09-30 │ 0                 │ 1255               │"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FB = df[(df[:Company] .== \"FB\"),:]\n",
    "AAPL = df[(df[:Company] .== \"AAPL\"),:]\n",
    "AMZN = df[(df[:Company] .== \"AMZN\"),:]\n",
    "NFLX = df[(df[:Company] .== \"NFLX\"),:]\n",
    "GOOG = df[(df[:Company] .== \"GOOG\"),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_data = FB[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(fb_data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = fb_data[:Returns]\n",
    "features = fb_data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_data = AAPL[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(aapl_data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = aapl_data[:Returns]\n",
    "features = aapl_data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_data = AMZN[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(amzn_data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = amzn_data[:Returns]\n",
    "features = amzn_data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nflx_data = NFLX[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(nflx_data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = nflx_data[:Returns]\n",
    "features = nflx_data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goog_data = GOOG[shuffle(1:end), :]\n",
    "\n",
    "train_proportion = 0.6\n",
    "n = size(goog_data, 1)\n",
    "\n",
    "ntrain = convert(Int, round(train_proportion*n))\n",
    "\n",
    "target = goog_data[:Returns]\n",
    "features = goog_data[:, [:\"Reddit Post Count\", :\"Twitter Post Count\", :\"Reddit Upvote Sum\"]]\n",
    "\n",
    "train_x = features[1:ntrain, :]\n",
    "test_x = features[ntrain+1:end, :]\n",
    "train_y = target[1:ntrain]\n",
    "test_y = target[ntrain+1:end]\n",
    "\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769230769230769"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [convert(Matrix, train_x) ones(ntrain)]\n",
    "X_test = [convert(Matrix, test_x) ones(size(test_x, 1))]\n",
    "\n",
    "ybool_train = (train_y .>= 0) \n",
    "ybool_test = (test_y .>= 0)\n",
    "\n",
    "n = size(ybool_test, 1)\n",
    "\n",
    "loss = 1/ntrain*LogisticLoss()\n",
    "λ = 0.1\n",
    "reg = λ*QuadReg()\n",
    "w = proxgrad(loss, reg, X_train, ybool_train, maxiters=200000, stepsize = 0.01)\n",
    "\n",
    "yhat = impute(loss, X_test*w)\n",
    "\n",
    "(n - sum(yhat .== ybool_test)) / n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
