{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import searchtweets\n",
    "from searchtweets import load_credentials\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from searchtweets import load_credentials\n",
    "from searchtweets import gen_rule_payload\n",
    "from searchtweets import collect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    search_tweets_premium = dict(\n",
    "        account_type = 'premium',\n",
    "        endpoint = 'https://api.twitter.com/1.1/tweets/search/fullarchive/prod.json',\n",
    "        consumer_key = 'p4dL1DlwWrEDKpi3NyAuVSZ1c',\n",
    "        consumer_secret = 'YmcryArWJY65urO103AXOCNoKpNcFEzHvuuiIT40XXO5QMeOLw'\n",
    "\n",
    "    )\n",
    ")\n",
    "\n",
    "#Create a yaml file that you'll need for API request\n",
    "with open('twitter_keys_fullarchive.yaml', 'w') as config_file:\n",
    "    yaml.dump(config, config_file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAKkPIQEAAAAA02DwMS08pdQt30MqUAoaj6JWgoY%3DplTTMgGqaEZvHrQiwrj4cgJyfa9Q6xs71s05YxfHDE6CaAJXqC', 'endpoint': 'https://api.twitter.com/1.1/tweets/search/fullarchive/prod.json', 'extra_headers_dict': None}\n"
     ]
    }
   ],
   "source": [
    "#Generate a bearer token\n",
    "premium_search_args = load_credentials(\"twitter_keys_fullarchive.yaml\",\n",
    "                                       yaml_key=\"search_tweets_premium\",\n",
    "                                       env_overwrite=False)\n",
    "print(premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\":\"FB\",\"toDate\":\"202009010000\",\"fromDate\":\"202008010000\",\"bucket\":\"day\"}\n"
     ]
    }
   ],
   "source": [
    "#Define a query for search results\n",
    "rule = gen_rule_payload('FB', results_per_call=500, from_date=\"2020-08-01\", to_date=\"2020-09-01\", count_bucket = \"day\")\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timePeriod': '202008010000', 'count': 1234}, {'timePeriod': '202008020000', 'count': 810}, {'timePeriod': '202008030000', 'count': 1470}, {'timePeriod': '202008040000', 'count': 1176}, {'timePeriod': '202008050000', 'count': 835}, {'timePeriod': '202008060000', 'count': 1104}, {'timePeriod': '202008070000', 'count': 1247}, {'timePeriod': '202008080000', 'count': 696}, {'timePeriod': '202008090000', 'count': 1523}, {'timePeriod': '202008100000', 'count': 938}, {'timePeriod': '202008110000', 'count': 1048}, {'timePeriod': '202008120000', 'count': 976}, {'timePeriod': '202008130000', 'count': 829}, {'timePeriod': '202008140000', 'count': 1456}, {'timePeriod': '202008150000', 'count': 1904}, {'timePeriod': '202008160000', 'count': 592}, {'timePeriod': '202008170000', 'count': 904}, {'timePeriod': '202008180000', 'count': 1124}, {'timePeriod': '202008190000', 'count': 1142}, {'timePeriod': '202008200000', 'count': 1144}, {'timePeriod': '202008210000', 'count': 923}, {'timePeriod': '202008220000', 'count': 513}, {'timePeriod': '202008230000', 'count': 826}, {'timePeriod': '202008240000', 'count': 885}, {'timePeriod': '202008250000', 'count': 983}, {'timePeriod': '202008260000', 'count': 3472}, {'timePeriod': '202008270000', 'count': 1740}, {'timePeriod': '202008280000', 'count': 713}, {'timePeriod': '202008290000', 'count': 431}, {'timePeriod': '202008300000', 'count': 425}, {'timePeriod': '202008310000', 'count': 1002}]\n"
     ]
    }
   ],
   "source": [
    "#Stream the results based on the query\n",
    "tweets = collect_results(rule, max_results = 500, result_stream_args = premium_search_args)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a Facebook dataframe that contains the daily count of August on Twitter\n",
    "Facebook_list = []\n",
    "for tweet in tweets:\n",
    "    date = tweet[\"timePeriod\"]\n",
    "    count = tweet[\"count\"]\n",
    "    Facebook_list.append({'date': date, 'count': count})\n",
    "Facebook = pd.DataFrame(Facebook_list, columns = ['date', 'count'])\n",
    "Facebook['date'] = pd.to_datetime(Facebook['date'])\n",
    "Facebook['date'] = Facebook['date'].dt.strftime('%y-%m-%d')\n",
    "Facebook['Company'] = \"Facebook\"\n",
    "Facebook['Ticker Symbol'] = 'FB'\n",
    "Facebook['Source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct an Apple dataframe that contains the daily count of August on Twitter\n",
    "rule = gen_rule_payload('AAPL', results_per_call=500, from_date=\"2020-08-01\", to_date=\"2020-09-01\", count_bucket = \"day\")\n",
    "tweets = collect_results(rule, max_results = 500, result_stream_args = premium_search_args)\n",
    "\n",
    "Apple_list = []\n",
    "for tweet in tweets:\n",
    "    date = tweet[\"timePeriod\"]\n",
    "    count = tweet[\"count\"]\n",
    "    Apple_list.append({'date': date, 'count': count})\n",
    "Apple = pd.DataFrame(Apple_list, columns = ['date', 'count'])\n",
    "Apple['date'] = pd.to_datetime(Apple['date'])\n",
    "Apple['date'] = Apple['date'].dt.strftime('%y-%m-%d')\n",
    "Apple['Company'] = \"Apple\"\n",
    "Apple['Ticker Symbol'] = 'AAPL'\n",
    "Apple['Source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct an Amazon dataframe that contains the daily count of August on Twitter\n",
    "rule = gen_rule_payload('AMZN', results_per_call=500, from_date=\"2020-08-01\", to_date=\"2020-09-01\", count_bucket = \"day\")\n",
    "tweets = collect_results(rule, max_results = 500, result_stream_args = premium_search_args)\n",
    "\n",
    "Amazon_list = []\n",
    "for tweet in tweets:\n",
    "    date = tweet[\"timePeriod\"]\n",
    "    count = tweet[\"count\"]\n",
    "    Amazon_list.append({'date': date, 'count': count})\n",
    "Amazon = pd.DataFrame(Amazon_list, columns = ['date', 'count'])\n",
    "Amazon['date'] = pd.to_datetime(Amazon['date'])\n",
    "Amazon['date'] = Amazon['date'].dt.strftime('%y-%m-%d')\n",
    "Amazon['Company'] = \"Amazon\"\n",
    "Amazon['Ticker Symbol'] = 'AMZN'\n",
    "Amazon['Source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a Netflix dataframe that contains the daily count of August on Twitter\n",
    "rule = gen_rule_payload('NFLX', results_per_call=500, from_date=\"2020-08-01\", to_date=\"2020-09-01\", count_bucket = \"day\")\n",
    "tweets = collect_results(rule, max_results = 500, result_stream_args = premium_search_args)\n",
    "\n",
    "Netflix_list = []\n",
    "for tweet in tweets:\n",
    "    date = tweet[\"timePeriod\"]\n",
    "    count = tweet[\"count\"]\n",
    "    Netflix_list.append({'date': date, 'count': count})\n",
    "Netflix = pd.DataFrame(Netflix_list, columns = ['date', 'count'])\n",
    "Netflix['date'] = pd.to_datetime(Netflix['date'])\n",
    "Netflix['date'] = Netflix['date'].dt.strftime('%y-%m-%d')\n",
    "Netflix['Company'] = \"Netflix\"\n",
    "Netflix['Ticker Symbol'] = 'NFLX'\n",
    "Netflix['Source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a Google dataframe that contains the daily count of August on Twitter\n",
    "rule = gen_rule_payload('GOOGL', results_per_call=500, from_date=\"2020-08-01\", to_date=\"2020-09-01\", count_bucket = \"day\")\n",
    "tweets = collect_results(rule, max_results = 500, result_stream_args = premium_search_args)\n",
    "\n",
    "Google_list = []\n",
    "for tweet in tweets:\n",
    "    date = tweet[\"timePeriod\"]\n",
    "    count = tweet[\"count\"]\n",
    "    Google_list.append({'date': date, 'count': count})\n",
    "Google = pd.DataFrame(Google_list, columns = ['date', 'count'])\n",
    "Google['date'] = pd.to_datetime(Google['date'])\n",
    "Google['date'] = Google['date'].dt.strftime('%y-%m-%d')\n",
    "Google['Company'] = \"Google\"\n",
    "Google['Ticker Symbol'] = 'GOOGL'\n",
    "Google['Source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "      <th>Company</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20-08-01</td>\n",
       "      <td>250841</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>FB</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-08-01</td>\n",
       "      <td>98937</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-08-01</td>\n",
       "      <td>657</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-08-01</td>\n",
       "      <td>1233</td>\n",
       "      <td>Google</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-08-01</td>\n",
       "      <td>5004</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>20-08-31</td>\n",
       "      <td>1718</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>20-08-31</td>\n",
       "      <td>120889</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20-08-31</td>\n",
       "      <td>15051</td>\n",
       "      <td>Apple</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>20-08-31</td>\n",
       "      <td>383185</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>FB</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>20-08-31</td>\n",
       "      <td>1002</td>\n",
       "      <td>Google</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   count   Company Ticker   Source\n",
       "0    20-08-01  250841  Facebook     FB  Twitter\n",
       "1    20-08-01   98937    Amazon   AMZN  Twitter\n",
       "2    20-08-01     657   Netflix   NFLX  Twitter\n",
       "3    20-08-01    1233    Google  GOOGL  Twitter\n",
       "4    20-08-01    5004     Apple   AAPL  Twitter\n",
       "..        ...     ...       ...    ...      ...\n",
       "150  20-08-31    1718   Netflix   NFLX  Twitter\n",
       "151  20-08-31  120889    Amazon   AMZN  Twitter\n",
       "152  20-08-31   15051     Apple   AAPL  Twitter\n",
       "153  20-08-31  383185  Facebook     FB  Twitter\n",
       "154  20-08-31    1002    Google  GOOGL  Twitter\n",
       "\n",
       "[155 rows x 5 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the companies into one DataFrame\n",
    "FAANG = [Facebook, Apple, Amazon, Netflix, Google]\n",
    "faang_df = pd.concat(FAANG)\n",
    "faang_df.sort_values(by='date', inplace=True, ascending=True)\n",
    "faang_df = faang_df.reset_index(drop = True)\n",
    "faang_df = faang_df.rename(columns = {\"Ticker Symbol\": \"Ticker\"})\n",
    "faang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_df.to_csv('Twiiter_Faang1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
